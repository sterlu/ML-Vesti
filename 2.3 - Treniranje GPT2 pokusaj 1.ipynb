{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.3 - Treniranje gpt2 pokusaj 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFCXqFL61oBW"
      },
      "source": [
        "# !pip install transformers tokenizers datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLc92zfzGjEM",
        "outputId": "e80f5f22-d99c-48c2-b731-7071dabe52e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OAXhTR91yyo"
      },
      "source": [
        "input_filename = \"naslovi_large.input\"\n",
        "dataset_filename = input_filename + '.prepared'\n",
        "pretrained_model_name = 'gpt2'\n",
        "new_model_name = pretrained_model_name + '_1'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGVyAnR616yT"
      },
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/content/drive/MyDrive/ML-Vesti/naslovi-tokenizer.json\")\n",
        "tokenizer.pad_token = \"<pad>\"\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7u9bGih2d3j",
        "outputId": "8caae171-f563-4a9d-d5d6-c497f99dea4d"
      },
      "source": [
        "from datasets import load_dataset\n",
        "# datasets = load_dataset('text', data_files=dataset_filename, split=\"train[90%],validate\")\n",
        "eval, train = load_dataset('text', data_files='/content/drive/MyDrive/ML-Vesti/' + dataset_filename, split=['train[:10%]', 'train[10%:]'])\n",
        "def prepare_for_trainer(example):\n",
        "  tokenized = tokenizer(example['text'], truncation=True, padding='max_length', max_length=20)\n",
        "  tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "  return tokenized\n",
        "tokenized_train = train.map(prepare_for_trainer, num_proc=2, remove_columns=[\"text\"])\n",
        "tokenized_eval = eval.map(prepare_for_trainer, num_proc=2, remove_columns=[\"text\"])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-0fd47dc85df26713\n",
            "Reusing dataset text (/root/.cache/huggingface/datasets/text/default-0fd47dc85df26713/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-0fd47dc85df26713/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-78b36d7e3a78ed29.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-0fd47dc85df26713/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-80b708a0e7248f01.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-0fd47dc85df26713/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-71bd1bf1961b31f9.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-0fd47dc85df26713/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-31540bef9eae1871.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ofZqnie2YFK"
      },
      "source": [
        "from transformers import Trainer, AutoConfig, AutoModelForCausalLM, TrainingArguments\n",
        "\n",
        "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name)\n",
        "# model.to('cuda:0')\n",
        "training_args = TrainingArguments(\n",
        "    # new_model_name,\n",
        "    output_dir='/content/drive/MyDrive/ML-Vesti/' + new_model_name,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=5e-3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy='epoch',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=256,\n",
        "    per_device_eval_batch_size=256,\n",
        "    save_total_limit=3,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    # prediction_loss_only=True,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCCTsE68F8c3",
        "outputId": "6ca77d41-cb0a-4830-85f3-01416a7a7b98"
      },
      "source": [
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        training_args.local_rank,\n",
        "        training_args.device,\n",
        "        training_args.n_gpu,\n",
        "        bool(training_args.local_rank != -1),\n",
        "        training_args.fp16,\n",
        "    )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8GKyjV1yelM"
      },
      "source": [
        "# import gc\n",
        "# import torch \n",
        "# model = None\n",
        "# trainer = None\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nECjRd3U33Xc",
        "outputId": "a66c38f7-5577-4310-d53e-0b3416916552"
      },
      "source": [
        "train_result = trainer.train()\n",
        "trainer.save_model('/content/drive/MyDrive/ML-Vesti/modeli/' + new_model_name)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1127951\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 256\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 44070\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44070' max='44070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [44070/44070 9:41:11, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.661600</td>\n",
              "      <td>4.275274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.190500</td>\n",
              "      <td>4.844938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.696600</td>\n",
              "      <td>0.495148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.398200</td>\n",
              "      <td>0.273840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.272200</td>\n",
              "      <td>0.169735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.184000</td>\n",
              "      <td>0.066047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.134800</td>\n",
              "      <td>0.034765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.091900</td>\n",
              "      <td>0.019507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.062100</td>\n",
              "      <td>0.010518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.042900</td>\n",
              "      <td>0.005724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-4407\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-4407/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-4407/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-4407/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-4407/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-8814\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-8814/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-8814/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-8814/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-8814/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-13221\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-13221/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-13221/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-13221/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-13221/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-17628\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-17628/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-17628/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-17628/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-17628/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-4407] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-22035\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-22035/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-22035/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-22035/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-22035/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-8814] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-26442\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-26442/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-26442/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-26442/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-26442/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-13221] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-30849\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-30849/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-30849/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-30849/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-30849/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-17628] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-35256\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-35256/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-35256/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-35256/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-35256/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-22035] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-39663\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-39663/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-39663/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-39663/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-39663/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-26442] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 125328\n",
            "  Batch size = 256\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-44070\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-44070/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-44070/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-44070/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-44070/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_1/checkpoint-30849] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/modeli/gpt2_1\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/modeli/gpt2_1/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/modeli/gpt2_1/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/modeli/gpt2_1/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/modeli/gpt2_1/special_tokens_map.json\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m-c2dyTQLLk",
        "outputId": "67b35358-d144-40a7-97f1-0af0e55ae2fc"
      },
      "source": [
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained('/content/drive/MyDrive/ML-Vesti/modeli/' + new_model_name)\n",
        "model.config.pad_token_id = 1\n",
        "\n",
        "for temp in np.linspace(0.2, 2, 10):\n",
        "    print()\n",
        "    print(\"###### Temperature: \" + str(temp))\n",
        "    for i in range(0, 5):\n",
        "        out = model.generate(do_sample=True, temperature=temp)[0]\n",
        "        print(tokenizer.decode(out, skip_special_tokens=True))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file /content/drive/MyDrive/ML-Vesti/modeli/gpt2_1/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/ML-Vesti/modeli/gpt2_1/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/ML-Vesti/modeli/gpt2_1.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "###### Temperature: 0.2\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "\n",
            "###### Temperature: 0.4\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "\n",
            "###### Temperature: 0.6000000000000001\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "\n",
            "###### Temperature: 0.8\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim zajedničkim\n",
            "SrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbiji njimaSrbiji njimašćušćušću\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli njima njima njima njima njima njima\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM otkriva JOŠ otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli njima njima njima njima njima\n",
            "\n",
            "###### Temperature: 1.0\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli\n",
            "SKISKI VOJSKA VOJSKA VOJSKA mnoge mnoge mnoge mnoge mnoge mnoge mnoge mnoge mnoge mnoge mnoge mnoge mnoge mnoge\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva\n",
            "\n",
            "###### Temperature: 1.2\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli njima Kragujevca njima njima njima njima njima\n",
            "DOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOM ZAJEDNO ZAJEDNO\n",
            "DOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOMDOM\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli kojim\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva\n",
            "\n",
            "###### Temperature: 1.4000000000000001\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM Tuzli Tuzli Tuzli Tuzli Tuzli Tuzli njima njima njima njima njima\n",
            " GRI GRI GRI GRI GRI GRI GRI GRI GRI GRI GRI GRI GRI GRI GRI3535 otkriva otkriva\n",
            " RUSKI RUSKI RUSKI RUSKI RUSKI RUSKI RUSKI RUSKI RUSKI RUSKI RUSKI RUSKI našoj javnog javnog otkriva javnog otkriva otkriva\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM otkriva Tuzli Tuzli njima njima njima njima njima njima njima\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva\n",
            "\n",
            "###### Temperature: 1.6\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE uputila uputila uputila uputila uputila uputila uputila uputila uputila uputila uputila\n",
            "MilijarderMilijarderMilijarderMilijarderMilijarderMilijarderMilijarderMilijarderMilijarderkomkomkomkomkomkomkomkom5858\n",
            "JapanJapanJapanJapanJapanJapanJapanJapanJapanJapanJapanJapanJapan MORAJU MORAJU MORAJU MORAJU MORAJU MORAJU\n",
            "SKISKI VOJSKA VOJSKA VOJSKA mnoge poze mnoge mnoge mnoge mnoge mnoge mnoge mnoge mnogercima mnoge mnoge mnoge\n",
            "SrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbijiSrbiji lažne njima njima njima njimašćušću\n",
            "\n",
            "###### Temperature: 1.8\n",
            " SRPSKIM SRPSKIM SRPSKIM SRPSKIM SRPSKIM SRPSKIM SRPSKIM SRPSKIM SRPSKIM javnog javnog njima javnog javnog javnog otkriva otkriva otkriva otkriva\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva otkriva\n",
            "NSNSNSNSNSNSNSNSNSNSNSNSNSNS DOKTO večeri otkriva otkriva otkriva\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE otkriva JEDNU otkriva verovao otkriva otkriva otkriva otkriva otkriva otkriva\n",
            "NSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIMNSKIM HILJADA HILJADA HILJADA HILJADA HILJADA HILJADA HILJADA HILJADA HILJADA HILJADA\n",
            "\n",
            "###### Temperature: 2.0\n",
            "TomaTomaTomaTomaTomaTomaTomaTomaTomaTomaTomaToma tamo jedna jedna jedna otkriva otkriva otkriva\n",
            "SKISKI VOJSKA VOJSKA VOJSKA činje činje činje činje činje službi stvo podršci i podržao i i i podržao\n",
            " KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE KUĆE sveštenika otkriva sveštenika otkriva otkriva otkriva uputila otkriva otkriva otkriva\n",
            "JapanJapanJapanJapanJapanJapanJapanJapanJapan San vakcine Alo otkriva Alo Alo otkriva otkriva otkriva otkriva\n",
            "barimabarimabarimabarimabarimabarimabarimabarimabarimabarima večeri večeri večeri večeri večeri večeri večeri večeri Londonu\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}