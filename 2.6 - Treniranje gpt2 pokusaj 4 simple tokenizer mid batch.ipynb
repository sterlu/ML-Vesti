{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.6 - Treniranje gpt2 pokusaj 4 simple tokenizer mid batch",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFCXqFL61oBW"
      },
      "source": [
        "!pip install transformers tokenizers datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLc92zfzGjEM",
        "outputId": "69f0a90b-17c9-45a8-bceb-558ad9035358"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OAXhTR91yyo"
      },
      "source": [
        "input_filename = \"naslovi_new.input\"\n",
        "dataset_filename = input_filename + '.prepared'\n",
        "pretrained_model_name = 'gpt2'\n",
        "new_model_name = pretrained_model_name + '_4'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGVyAnR616yT"
      },
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/content/drive/MyDrive/ML-Vesti/naslovi-simple-tokenizer.json\")\n",
        "tokenizer.pad_token = \"<pad>\"\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7u9bGih2d3j",
        "outputId": "9a71c23d-84c2-40d9-f662-64951d3bfe49"
      },
      "source": [
        "from datasets import load_dataset\n",
        "# datasets = load_dataset('text', data_files=dataset_filename, split=\"train[90%],validate\")\n",
        "eval, train = load_dataset('text', data_files='/content/drive/MyDrive/ML-Vesti/' + dataset_filename, split=['train[:10%]', 'train[10%:]'])\n",
        "def prepare_for_trainer(example):\n",
        "  tokenized = tokenizer(example['text'], truncation=True, padding='max_length', max_length=20)\n",
        "  tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "  return tokenized\n",
        "tokenized_train = train.map(prepare_for_trainer, num_proc=2, remove_columns=[\"text\"])\n",
        "tokenized_eval = eval.map(prepare_for_trainer, num_proc=2, remove_columns=[\"text\"])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-9b16dadd29989af1\n",
            "Reusing dataset text (/root/.cache/huggingface/datasets/text/default-9b16dadd29989af1/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-9b16dadd29989af1/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-08cefdf458753fe3.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-9b16dadd29989af1/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-7045a3e43f5a227b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-9b16dadd29989af1/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-6d7f1153ad569538.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-9b16dadd29989af1/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-989d2cd40795db8a.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ofZqnie2YFK"
      },
      "source": [
        "from transformers import Trainer, AutoConfig, AutoModelForCausalLM, TrainingArguments\n",
        "\n",
        "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name)\n",
        "# model.to('cuda:0')\n",
        "training_args = TrainingArguments(\n",
        "    # new_model_name,\n",
        "    output_dir='/content/drive/MyDrive/ML-Vesti/' + new_model_name,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy='epoch',\n",
        "    num_train_epochs=7,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=128,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    # prediction_loss_only=True,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCCTsE68F8c3",
        "outputId": "2f0fd591-7c8d-4e13-80ac-6fb84cafed22"
      },
      "source": [
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        training_args.local_rank,\n",
        "        training_args.device,\n",
        "        training_args.n_gpu,\n",
        "        bool(training_args.local_rank != -1),\n",
        "        training_args.fp16,\n",
        "    )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8GKyjV1yelM"
      },
      "source": [
        "# import gc\n",
        "# import torch \n",
        "# model = None\n",
        "# trainer = None\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nECjRd3U33Xc",
        "outputId": "2875c549-8d9b-4ee8-cd9e-a15e46aa6880"
      },
      "source": [
        "train_result = trainer.train()\n",
        "trainer.save_model('/content/drive/MyDrive/ML-Vesti/modeli/' + new_model_name)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1968703\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 107667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='107667' max='107667' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [107667/107667 7:07:58, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.313200</td>\n",
              "      <td>3.908457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.099800</td>\n",
              "      <td>3.663588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.990500</td>\n",
              "      <td>3.543822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.916900</td>\n",
              "      <td>3.472665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.880600</td>\n",
              "      <td>3.431994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.855900</td>\n",
              "      <td>3.407330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.839900</td>\n",
              "      <td>3.398161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 218745\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-15381\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-15381/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-15381/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-15381/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-15381/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 218745\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-30762\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-30762/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-30762/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-30762/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-30762/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 218745\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-46143\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-46143/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-46143/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-46143/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-46143/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-15381] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 218745\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-61524\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-61524/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-61524/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-61524/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-61524/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-30762] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 218745\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-76905\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-76905/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-76905/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-76905/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-76905/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-46143] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 218745\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-92286\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-92286/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-92286/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-92286/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-92286/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-61524] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 218745\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-107667\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-107667/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-107667/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-107667/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-107667/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/ML-Vesti/gpt2_4/checkpoint-76905] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /content/drive/MyDrive/ML-Vesti/modeli/gpt2_4\n",
            "Configuration saved in /content/drive/MyDrive/ML-Vesti/modeli/gpt2_4/config.json\n",
            "Model weights saved in /content/drive/MyDrive/ML-Vesti/modeli/gpt2_4/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/ML-Vesti/modeli/gpt2_4/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/ML-Vesti/modeli/gpt2_4/special_tokens_map.json\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m-c2dyTQLLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ddaf9e0-aa44-4710-9395-19fd4e8f8b41"
      },
      "source": [
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained('/content/drive/MyDrive/ML-Vesti/modeli/' + new_model_name)\n",
        "model.config.pad_token_id = 1\n",
        "\n",
        "for temp in np.linspace(0.2, 2, 10):\n",
        "    print()\n",
        "    print(\"###### Temperature: \" + str(temp))\n",
        "    for i in range(0, 5):\n",
        "        out = model.generate(do_sample=True, temperature=temp)[0]\n",
        "        print(tokenizer.decode(out, skip_special_tokens=True))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file /content/drive/MyDrive/ML-Vesti/modeli/gpt2_4/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/ML-Vesti/modeli/gpt2_4/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/ML-Vesti/modeli/gpt2_4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "###### Temperature: 0.2\n",
            "\n",
            "\n",
            "!\n",
            "\n",
            "je, a onda je! ( VIDEO )\n",
            "\n",
            "###### Temperature: 0.4\n",
            "Ovo su u Srbiji!\n",
            "u :\n",
            ",,,,,... dana\n",
            "\n",
            "se, a onda je!!\n",
            "\n",
            "###### Temperature: 0.6000000000000001\n",
            "Posle toga što je rekao o, je u zatvoru!\n",
            "je da je, ali je U!\n",
            "Evo šta je sve pronađeno u\n",
            "i u osmini finala, a evo kako su se na kraju\n",
            "se na,, a onda je usledio šok!\n",
            "\n",
            "###### Temperature: 0.8\n",
            "Nakon svađe, otac i sin ( 14 ) pronašli u stanu\n",
            "U Srbiji su se čule, a već je sve jasno\n",
            "U na i GODINE GODINE!\n",
            "je da su joj se!, pa je! ( VIDEO )\n",
            ", i dobili za\n",
            "\n",
            "###### Temperature: 1.0\n",
            "Bivši trener Zvezde OTKRIO plan koji je oduševio Evropu ( FOTO )\n",
            "Vučić u Vašingtonu sa : nije opcija, ne postoje stvari\n",
            "Nakon ŽESTOKE svađe sa Borom PEVAČICOM, ONA je jedna stvar za to!\n",
            "me, nije ni znao gde će!\n",
            "Ovo je pet albuma koje bi trebalo da preslušate danas ( FOTO )\n",
            "\n",
            "###### Temperature: 1.2\n",
            "Ana Nikolić : Zašto je i gde živi, što svi kažu da ćemo to da radite\n",
            "U udesu motocikla autobusa oko 25 povređeno! Povređena 3 pešaka!\n",
            "Pevačica se opustila u bikini od automobila ( FOTO )\n",
            "Kako je izgledao rat kod kuće : Svi iz su bili u redu\n",
            ": Ne želimo da se borimo taksi, ali i dijalog Srbije i članica stranke!\n",
            "\n",
            "###### Temperature: 1.4000000000000001\n",
            "Pevačica ne prestaje da PLAČE?! Evo ŠTA su od TUGE : Izgleda kao kod Slobe\n",
            "Zvezda se sprema za finale ( FOTO )\n",
            "Vučić : Srbi, se na TV! Ako vidite OVU cifru smo u nedelju ( FOTO\n",
            "Evo do kojoj može uticati da su OVE PROMENE POSLEDICE, a ko ne?\n",
            "Na današnji dan rođen je! bolesnika na jugu Srbije\n",
            "\n",
            "###### Temperature: 1.6\n",
            "od samo 2 SASTOJKA SAVETA može kao! sve TAJNE GRUDI u programu\n",
            "Zbog duga 10. 000 dolara mesečno I MASKE u\n",
            "iz Hrvatske u SAD : ga od muke do\n",
            "Predsednik SAD će danas sa patrijarhom 1244 o Kosovu : ih već u!\n",
            "Još jedna zvezda se oporavila videti reči u zgradi\n",
            "\n",
            "###### Temperature: 1.8\n",
            "Na spisku više od 200 predmeta, bez maski vozila i na Gradini i Zvezdari\n",
            "Pogledajte reakciju na Tviteru! Sve po prvi put od odlaska Partizana\n",
            "Kad bude više minuta svi je znamo sa nekim fudbalerom i ne daju mu NIŠTA što se\n",
            "Zbog velikog na aerodromu u Podgorici stigao novi srpski klub! ( FOTO )\n",
            "Ovo NIKO nema ništa u životu! Zbog ove scene sada možete i pre\n",
            "\n",
            "###### Temperature: 2.0\n",
            "Šta donosi odluku vlade za povećanje temperature vakcine protiv korone? više vremena\n",
            "Pevačica ŠOKIRALA svet dirljivom stopama izjavom o novoj ljubavi, o njoj BRUJE SVI DETALJI NOVE DETALJE i OTKRILA\n",
            "i zvanično strelac sportista! Na ovaj dan mu šalje više stotina pesama kandidata, svi u drugom\n",
            "Dr Janković apeluje, ili zabrana putovanja, ALI ĆEMO VEĆI\n",
            "Evo zašto je to dobro! ( VIDEO i FOTO )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncz3qCIVypDU",
        "outputId": "c56dc00e-f5dd-44fe-c7c8-7be9a3d6058e"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-a94002ea-f93f-02c5-c7a3-6842be217f8f)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}